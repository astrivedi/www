@InProceedings{10.1007/978-3-030-17462-0_27,
author="Hahn, Ernst Moritz
and Perez, Mateo
and Schewe, Sven
and Somenzi, Fabio
and Trivedi, Ashutosh
and Wojtczak, Dominik",
editor="Vojnar, Tom{\'a}{\v{s}}
and Zhang, Lijun",
title="Omega-Regular Objectives in Model-Free Reinforcement Learning",
booktitle="Tools and Algorithms for the Construction and Analysis of Systems",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="395--412",
abstract="We provide the first solution for model-free reinforcement learning of {\$}{\$}{\backslash}omega {\$}{\$}-regular objectives for Markov decision processes (MDPs). We present a constructive reduction from the almost-sure satisfaction of {\$}{\$}{\backslash}omega {\$}{\$}-regular objectives to an almost-sure reachability problem, and extend this technique to learning how to control an unknown model so that the chance of satisfying the objective is maximized. We compile {\$}{\$}{\backslash}omega {\$}{\$}-regular properties into limit-deterministic B{\"u}chi automata instead of the traditional Rabin automata; this choice sidesteps difficulties that have marred previous proposals. Our approach allows us to apply model-free, off-the-shelf reinforcement learning algorithms to compute optimal strategies from the observations of the MDP. We present an experimental evaluation of our technique on benchmark learning problems.",
isbn="978-3-030-17462-0"
}

