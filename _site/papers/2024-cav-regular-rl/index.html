<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>

  <title>
    
      Regular Reinforcement Learning 路 Ashutosh Trivedi
    
  </title>

  <meta name="description"
        content="My research develops formal methods for reinforcement learning and trustworthy AI,  with a focus on verification and accountability in high-stakes decision-making systems.
"/>

  <link rel="stylesheet" href="/assets/css/main.css"/>

  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Ashutosh Trivedi",
    "url": "https://ashutoshtrivedi.com",
    "image": "https://ashutoshtrivedi.com/assets/img/portrait.jpg",
    "jobTitle": "Associate Professor of Computer Science",
    "affiliation": {
      "@type": "Organization",
      "name": "University of Colorado Boulder",
      "url": "https://www.colorado.edu"
    },
    "alumniOf": [
      {
        "@type": "CollegeOrUniversity",
        "name": "University of Warwick"
      }
    ],
    "sameAs": [
      "https://www.wikidata.org/wiki/Q102112267",
      "https://scholar.google.com/citations?user=9WDXyy4AAAAJ",
      "https://orcid.org/0000-0001-9346-0126",
      "https://dblp.org/pid/06/5756.html"
    ]
  }
  </script>
</head>

  <body>
    <div class="container">
      <nav class="nav">
<a class="brand home-icon" href="/" aria-label="Home">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"
       width="22" height="22" fill="none"
       stroke="currentColor" stroke-width="2"
       stroke-linecap="round" stroke-linejoin="round">
    <path d="M3 10.5L12 3l9 7.5"/>
    <path d="M5 10v10h5v-6h4v6h5V10"/>
  </svg>
</a>

  <ul>
    <li><a href="/research/">Research</a></li>
    <li><a href="/publications/">Publications</a></li>
    <li><a href="/group/">Group</a></li>
    <li><a href="/teaching/">Teaching</a></li>
     <li><a href="/bio/">Bio</a></li>
    <li><a href="/contact/">Contact</a></li>
  </ul>
</nav>

      <article class="paper-page">
  <header>
    <h1>Regular Reinforcement Learning</h1>

<p class="paper-award"> CAV Distinguished Paper Award</p>



    
      <p><strong>Authors:</strong> Taylor Dohmen, Mateo Perez, Fabio Somenzi, Ashutosh Trivedi</p>
    

    <p>
      <strong>CAV</strong>
       (2024)
    </p>

    
      <p class="paper-tags">
        
          <a class="tag" href="/tags/top/">top</a>
        
          <a class="tag" href="/tags/award/">award</a>
        
          <a class="tag" href="/tags/formalrl/">formalrl</a>
        
          <a class="tag" href="/tags/trustworthyai/">trustworthyAI</a>
        
      </p>
    

    <p class="paper-links">
      <a href="/assets/papers/2024-cav-regular-rl.pdf">PDF</a>
       路 <a href="/assets/papers/2024-cav-regular-rl.bib" download>BibTeX</a>
      
      
      
       路 <a href="https://doi.org/10.1007/978-3-031-65633-0_9">DOI</a>
      
    </p>
  </header>

  
  <section>
  <h2>Abstract</h2>
  <p>In reinforcement learning, an agent incrementally refines a behavioral policy through a series of episodic interactions with its environment. This process can be characterized as explicit reinforcement learning, as it deals with explicit states and concrete transitions. Building upon the concept of symbolic model checking, we propose a symbolic variant of reinforcement learning, in which sets of states are represented through predicates and transitions are represented by predicate transformers. Drawing inspiration from regular model checking, we choose regular languages over the states as our predicates, and rational transductions as predicate transformations. We refer to this framework as regular reinforcement learning, and study its utility as a symbolic approach to reinforcement learning. Theoretically, we establish results around decidability, approximability, and efficient learnability in the context of regular reinforcement learning. Towards practical applications, we develop a deep regular reinforcement learning algorithm, enabled by the use of graph neural networks, and showcase the applicability and effectiveness of (deep) regular reinforcement learning through empirical evaluation on a diverse set of case studies. :contentReference[oaicite:1]{index=1}</p>

</section>

  

  <section>
    

  </section>
</article>

      <footer class="footer">
  漏 2025 Ashutosh Trivedi 路 University of Colorado Boulder
</footer>

    </div>
  </body>
</html>
