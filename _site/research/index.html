<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>

  <title>
    
      Research · Ashutosh Trivedi
    
  </title>

  <meta name="description"
        content="My research develops formal methods for reinforcement learning and trustworthy AI,  with a focus on verification and accountability in high-stakes decision-making systems.
"/>

  <link rel="stylesheet" href="/assets/css/main.css"/>

  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Ashutosh Trivedi",
    "url": "https://ashutoshtrivedi.com",
    "image": "https://ashutoshtrivedi.com/assets/img/portrait.jpg",
    "jobTitle": "Associate Professor of Computer Science",
    "affiliation": {
      "@type": "Organization",
      "name": "University of Colorado Boulder",
      "url": "https://www.colorado.edu"
    },
    "alumniOf": [
      {
        "@type": "CollegeOrUniversity",
        "name": "University of Warwick"
      }
    ],
    "sameAs": [
      "https://www.wikidata.org/wiki/Q102112267",
      "https://scholar.google.com/citations?user=9WDXyy4AAAAJ",
      "https://orcid.org/0000-0001-9346-0126",
      "https://dblp.org/pid/06/5756.html"
    ]
  }
  </script>
</head>

  <body>
    <div class="container">
      <nav class="nav">
<a class="brand home-icon" href="/" aria-label="Home">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"
       width="22" height="22" fill="none"
       stroke="currentColor" stroke-width="2"
       stroke-linecap="round" stroke-linejoin="round">
    <path d="M3 10.5L12 3l9 7.5"/>
    <path d="M5 10v10h5v-6h4v6h5V10"/>
  </svg>
</a>

  <ul>
    <li><a href="/research/">Research</a></li>
    <li><a href="/publications/">Publications</a></li>
    <li><a href="/group/">Group</a></li>
    <li><a href="/teaching/">Teaching</a></li>
     <li><a href="/bio/">Bio</a></li>
    <li><a href="/contact/">Contact</a></li>
  </ul>
</nav>

      <h1>Research</h1>
<p>
My research develops mathematically rigorous foundations for trustworthy artificial
intelligence. I study how learning-enabled and autonomous systems can be designed to
operate safely, fairly, and accountably, even in complex, uncertain, and high-stakes
settings. My work spans formal verification, reinforcement learning, explainability,
and the integration of logic-based reasoning with data-driven methods.
</p>

<p>
A unifying theme of my research is that intelligent systems should not only perform well,
but also admit principled reasoning about their behavior. To this end, I develop
specification-aware learning algorithms, symbolic abstractions, and hybrid reasoning
frameworks that enable verification, explanation, and accountability.
</p>

<div class="sectionline"></div>

<h2>Formal Methods for Reinforcement Learning</h2>
<p class="small">
Foundations for reasoning about learning agents beyond finite-state, episodic settings.
</p>
<p>
I investigate the foundational and algorithmic integration of formal methods with
reinforcement learning, aiming to enable reliable and structured decision-making in
complex environments. My work addresses settings where classical RL abstractions are
insufficient, such as temporal objectives, recursion, and symbolic or continuous state
spaces.
</p>

<ul class="small">
  <li>Translating logical specifications into learnable reward structures</li>
  <li>Symbolic and automata-theoretic abstractions (reward machines, regular languages)</li>
  <li>Reinforcement learning for recursive and branching MDPs</li>
  <li>Continuous-time and continuous-space RL grounded in physical models</li>
  <li>Asymmetrically-discounted and past-discounted objectives</li>
</ul>

<div class="sectionline"></div>

<h2>Trustworthy Reasoning with Learning and LLMs</h2>
<p class="small">
Combining learning with symbolic reasoning to produce explanations and guarantees.
</p>
<p>
I develop methods for enabling large language models (LLMs) to reason in ways that are
trustworthy, auditable, and verifiable. Rather than treating LLMs as monolithic predictors,
my work integrates them with symbolic tools such as formal logic, automata, and SMT solvers,
to produce explanations and decisions grounded in formal reasoning.
</p>

<p>
I design modular and multi-agent architectures that separate planning, reasoning, and
explanation, allowing LLMs to generate structured proofs, translate formal artifacts into
human-understandable explanations, and critique outputs for logical consistency and
regulatory compliance.
</p>

<div class="sectionline"></div>

<h2>AI, Software, and Accountability</h2>
<p class="small">
Auditing and debugging AI-driven software in legal- and social-critical domains.
</p>
<p>
I study the interplay between algorithmic decision-making, software systems, and legal
and ethical accountability. My research develops formal and data-driven techniques for
auditing, testing, and explaining software behavior in domains where correctness has
legal or societal consequences.
</p>

<ul class="small">
  <li>Detection and mitigation of algorithmic unfairness</li>
  <li>Regulatory and legal compliance for AI-driven software</li>
  <li>Metamorphic and relational testing in the absence of explicit specifications</li>
</ul>

<p>
Application domains include tax preparation software, juvenile justice, and public
services, where transparency and accountability are critical.
</p>
<p class="small">
Selected papers:
<a class="link" href="#">Parfait-ML</a>,
<a class="link" href="#">Metamorphic Testing of Tax Software</a>
</p>

<div class="sectionline"></div>

<h2>Secure &amp; Safe Cyber-Physical Systems (CPS)</h2>
<p class="small">
Formal guarantees for safety, security, and control under uncertainty.
</p>
<p>
I design provably correct and resilient controllers for safety-critical cyber-physical
systems. My work combines control theory, formal verification, and symbolic reasoning to
ensure safety and security in dynamic and uncertain environments.
</p>

<ul class="small">
  <li>Control barrier functions and Lyapunov-based methods</li>
  <li>Temporal-logic-based synthesis and verification</li>
  <li>Learning-enabled control with formal guarantees</li>
</ul>

<p class="small">
Selected papers:
<a class="link" href="#">Closure Certificates</a>,
<a class="link" href="#">Neural Control Barrier Certificates</a>
</p>

<div class="sectionline"></div>

<h2>Methods &amp; Themes</h2>
<p>
Across these areas, my research draws on formal verification (model checking, SMT, SOS),
reinforcement learning, automata theory, and program analysis. A recurring theme is the
design of intelligent systems whose learning behavior can be reasoned about, explained,
and held accountable.
</p>

      <footer class="footer">
  © 2025 Ashutosh Trivedi · University of Colorado Boulder
</footer>

    </div>
  </body>
</html>
