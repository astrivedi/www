<html>
<head>
<title> 
Trivedi/Voronin: Mixed Strategy Improvement Algorithm for Markov Decision Processes.</title>
 <link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
 <link href="../main.css" rel="stylesheet" type="text/css" />
</head>

<body>
<hr>
<h2>
Mixed Strategy Improvement Algorithm for Markov Decision Processes.
</h2><hr>

<i> 
<a href="http://www.ashutoshtrivedi.com/">Ashutosh Trivedi </a>
and Yuen-Lam Voronin.
</i>
<br><br>
One standard way of finding an optimal policy in a given Markov decision process
(MDP) is to set up a linear program whose (unique) optimal solution satisfies
the Bellman equation for the value vector of any optimal policy of that MDP. We
show that the dual of that standard linear program is closely related to the
probabilistic policies (or mixed strategies) of the MDP, and based on that
connection we propose a polynomial time policy-iteration algorithm.
<br>
<br>

<i> 
  Under review.
</i>
<hr>
<a href="mixedsia.pdf">PDF</a> &copy 2016.

</body>
</html>
